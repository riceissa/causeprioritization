---
title: Jacob Steinhardt’s views on AI safety
format: markdown
categories: AI_safety
...

<https://jsteinhardt.wordpress.com/2015/06/24/long-term-and-short-term-challenges-to-ensuring-the-safety-of-ai-systems/>

<http://lesswrong.com/r/discussion/lw/iyo/the_inefficiency_of_theoretical_discovery/a07j>

<http://lesswrong.com/lw/cyy/seeking_information_relevant_to_deciding_whether/6t83>

<http://lesswrong.com/lw/6ct/siais_shortterm_research_program/4eo6>

<http://lesswrong.com/lw/673/model_uncertainty_pascalian_reasoning_and/4cvy>

<http://lesswrong.com/lw/jgz/aalwa_ask_any_lesswronger_anything/acf5>

<http://lesswrong.com/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/9aij>

<http://lesswrong.com/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/99tj>

<http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/6mg5>

<http://lesswrong.com/lw/8k7/will_the_ems_save_us_from_the_robots/5bb4>

<http://lesswrong.com/lw/6w3/the_125000_summer_singularity_challenge/4kyb>

<http://lesswrong.com/lw/6oh/agifai_theorist_for_hire/4isk>

<https://www.openphilanthropy.org/sites/default/files/Jacob_Steinhardt_08-19-2015_%28public%29.pdf>

<http://effective-altruism.com/ea/1ca/my_current_thoughts_on_miris_highly_reliable/bee>

<http://effective-altruism.com/ea/14c/why_im_donating_to_miri_this_year/94l>

from 2011: "there is some absurdly high amount of unexplored ground in areas relating to whole brain emulations and brain-computer interfaces. Neither of these are particularly math-heavy, and it's likely that at there are parts of the problem that just require engineering or lab experience. My current estimate is that the more people working on WBE, the better. Also: the larger the fraction of the WBE community that cares about existential risks, the better." ([source](http://lesswrong.com/lw/8iz/studying_psychology_which_path_should_i_take_to/5b78))

he also appears in at least one of the MIRI--Holden conversations

From [this conversation](https://intelligence.org/wp-content/uploads/2014/02/01-21-2014-conversation-with-Jacob-Steinhardt.pdf):

> When I look at MIRI's website, some of the first things I see are things I
> disagree with. Not the mission statement — that's uncontroversial. But one of
> the first things I saw was the orthogonality thesis and some other thing I
> disagreed with.

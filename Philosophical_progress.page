---
title: Philosophical progress
format: markdown
categories: Cause_areas Philosophical_progress Philosophy Cause_prioritization
...

**Philosophical progress** seems like (1) a cause area in itself; (2) relevant to multiple
specific other cause areas; and (3) a part of [cause prioritization]().

Answers to philosophy questions have implications for altruism (see e.g. the work of MIRI and [Foundational Research Institute]()) and for specific cause areas (like [AI alignment]()).

For cause prioritization, answers to questions like how we discover our values or which beings count for moral consideration are relevant to deciding which causes to support. See e.g. [this post](https://www.openphilanthropy.org/blog/technical-and-philosophical-questions-might-affect-our-grantmaking "“Technical and Philosophical Questions That Might Affect Our Grantmaking”. Open Philanthropy Project. April 7, 2017. Retrieved February 21, 2018.") and [this report](https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood). In this sense topics like [population ethics]() are a subset of making general philosophical progress.

See some discussion about philosophical ability [here](http://lesswrong.com/lw/ua/the_level_above_mine/). See also [this Quora question](https://www.quora.com/unanswered/What-do-Wei-Dai-and-Eliezer-Yudkowsky-mean-by-philosophical-ability).

See also [this comment](http://lesswrong.com/lw/frp/train_philosophers_with_pearl_and_kahneman_not/ai2b "“Wei_Dai comments on Train Philosophers with Pearl and Kahneman, not Plato and Kant”. LessWrong. Retrieved February 21, 2018.") by Wei Dai.

Paul Christiano weighs in [here](http://lesswrong.com/lw/h8k/pascals_muggle_infinitesimal_priors_and_strong/d6n1).

# Moral Philosophy

- [Moral uncertainty](https://www.moraluncertainty.com/)


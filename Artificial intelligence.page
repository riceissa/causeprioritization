---
format: markdown
categories: artificial-intelligence a-cause existential-risks
...

# Summary

Importance
:    \<importance rating\>

Tractability
:    \<tractability rating\>

Neglectedness
:    \<neglectedness rating\>


<!-- keywords: ai siai miri singularity eliezer yudkowsky agi
               asi fai friendly ai
-->

[AI Impacts](http://www.aiimpacts.org/) is an informational site that "aims to improve our understanding of the likely impacts of human-level artificial intelligence".

The main EA organization working in this field seems to be [MIRI](http://intelligence.org/), which does relevant math research and sponsors forecasting projects like [AI Impacts](http://www.aiimpacts.org/).
FHI might also have more information.

[*Superintelligence: Paths, Dangers, Strategies*](http://www.amazon.com/dp/0199678111/ref=cm_sw_su_dp) by [Nick Bostrom](http://www.nickbostrom.com/) lays out a foundation for navigating scenarios where machine brains surpass human brains in general intelligence.

[Artificial General Intelligence](http://www.scholarpedia.org/article/Artificial_General_Intelligence)

[How large do you think the first Strong AI be\(lines of code, servers etc\)? • /r/artificial](https://www.reddit.com/r/artificial/comments/2qyg8j/how_large_do_you_think_the_first_strong_ai/cnathbn)

[Artificial Intelligence • /r/artificial](https://www.reddit.com/r/artificial/)

[Comparative Table of Cognitive Architectures \(started on October 27, 2009; last update: June 18, 2012\)](http://bicasociety.org/cogarch/architectures.htm)

# Importance

FIXME

# Tractability

FIXME

# Neglectedness

FIXME

# See also

- [Simulation hypothesis]()

# External links

- [CarlShulman comments on How does MIRI Know it Has a Medium Probability of Success?](http://lesswrong.com/lw/i7p/how_does_miri_know_it_has_a_medium_probability_of/9i5b)
- [Don’t Worry, Smart Machines Will Take Us With Them](http://nautil.us/issue/28/2050/dont-worry-smart-machines-will-take-us-with-them)
-   Jeff Kaufman's posts on AI safety:
    -   ["Looking into AI Risk"](http://www.jefftk.com/p/looking-into-ai-risk)
    -   ["Superintelligence Risk Project"](http://www.jefftk.com/p/superintelligence-risk-project)
    -   ["Conversation with Dario Amodei"](http://www.jefftk.com/p/conversation-with-dario-amodei)
    -   ["Conversation with Michael Littman"](http://www.jefftk.com/p/conversation-with-michael-littman)
    -   ["Superintelligence Risk Project Update"](http://www.jefftk.com/p/superintelligence-risk-project-update)

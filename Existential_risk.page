---
title: Existential risk
format: markdown
categories: Cause_areas
...

<!-- keywords:
exrisk xrisk x-risk
-->

An existential risk is one that threatens the entire future of humanity. More specifically, existential risks are those that threaten the extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development.

Anthropogenic risks are those that would be the result of human activity, and natural risks are those that would be caused by nature. There could also be risks from alien civilizations.

The Open Philanthropy Project with Good Venture is one of the main founders in this space as can be seen in their [grant database](https://www.openphilanthropy.org/giving/grants).

# Organizations
Main focus:  

- [Future of Humanity Institute](https://en.wikipedia.org/wiki/Future_of_Humanity_Institute)
- [Future of Life Institute](https://en.wikipedia.org/wiki/Future_of_Life_Institute)  
- [Global Catastrophic Risk Institute](http://gcrinstitute.org/)  
- [The Cambridge Centre for the Study of Existential Risk](https://en.wikipedia.org/wiki/Centre_for_the_Study_of_Existential_Risk)  
- [The Institute for Ethics and Emerging Technology](https://en.wikipedia.org/wiki/Institute_for_Ethics_and_Emerging_Technologies)  
- [Machine Intelligence Research Institute](https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute)  
- [Center for Security and Emerging Technology](https://cset.georgetown.edu/about-us/)  
- [OpenAI](https://en.wikipedia.org/wiki/OpenAI)  

Related:  

- [Center for New American Security](https://www.cnas.org)

# External links  
- [Existential risks website](http://www.existential-risk.org)
- [Existential risks by Nick Bostrom](https://nickbostrom.com/existential/risks.html)
- [Open Philanthropy Project review of Global Catastrophic Risks](https://www.openphilanthropy.org/research/cause-reports/global-catastrophic-risks/global-catastrophic-risks)
- [Global catastrophic risk on Wikipedia](https://en.wikipedia.org/wiki/Global_catastrophic_risk)

# See also
[This comment](http://effective-altruism.com/ea/9f/on_progress_and_prosperity/12p) that considers a "scorched earth" strategy in the context of differential intellectual progress (this is also something to think about regarding SIMADs).
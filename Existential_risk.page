---
title: Existential risk
format: markdown
categories: Cause_areas, prize
...

<!-- keywords:
exrisk xrisk x-risk
-->

An existential risk is one that threatens the entire future of humanity. More specifically, existential risks are those that threaten the extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development.

Anthropogenic risks are those that would be the result of human activity, and natural risks are those that would be caused by nature. There could also be risks from alien civilizations.

The Open Philanthropy Project with Good Venture is one of the main founders in this space as can be seen in their [grant database](https://www.openphilanthropy.org/giving/grants).

# Prize
The Future of Life Institute offers the Future of Life Award to individuals that help prevent existential risks ([source](https://futureoflife.org/2017/10/27/55-years-preventing-nuclear-attack-arkhipov-honored-inaugural-future-life-award/)).


# Organizations
Organizations working on a specific existential risk are only mentioned on the specific page for existential risk.

Main focus:  

- [Future of Humanity Institute](https://en.wikipedia.org/wiki/Future_of_Humanity_Institute)
- [Future of Life Institute](https://en.wikipedia.org/wiki/Future_of_Life_Institute)  
- [Global Catastrophic Risk Institute](http://gcrinstitute.org/)  
- [The Cambridge Centre for the Study of Existential Risk](https://en.wikipedia.org/wiki/Centre_for_the_Study_of_Existential_Risk)  
- [The Institute for Ethics and Emerging Technology](https://en.wikipedia.org/wiki/Institute_for_Ethics_and_Emerging_Technologies)  
- [Machine Intelligence Research Institute](https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute)  
- [Center for Security and Emerging Technology](https://cset.georgetown.edu/about-us/)  
- [OpenAI](https://en.wikipedia.org/wiki/OpenAI)  
- [AllFed](http://allfed.info/)

Related:  

- [Center for New American Security](https://www.cnas.org)


# List of existential risks
Technological x-risks:

- [AI safety]() (related: [Whole brain emulation]())
- [Biosecurity]()
- [Climate change]()
- [Nuclear security]()
- Other: [Emerging technologies assessment]()

Other anthropogenic x-risks:

- [Population control]()
- [Preventing totalitarianism]()

Natural x-risks:

- [Asteroids]()
- [Geomagnetic storms]()

Other:

- [Aliens]()
- Simulation shutdown (see: [Simulation hypothesis]())

# Broad interventions
Technologies that could potentially mitigate various existential risks:

- [Embryo selection]()
- [Forecasting]()
- [Surveillance]()

# Related concepts
- [Differential progress]()
- [Importance]()

# See also
- [Risks of astronomical suffering]()

# External links  
- [Existential risks website](http://www.existential-risk.org)
- [Existential risks by Nick Bostrom](https://nickbostrom.com/existential/risks.html)
- [Open Philanthropy Project review of Global Catastrophic Risks](https://www.openphilanthropy.org/research/cause-reports/global-catastrophic-risks/global-catastrophic-risks)
- [Global catastrophic risk on Wikipedia](https://en.wikipedia.org/wiki/Global_catastrophic_risk)
- [This comment](http://effective-altruism.com/ea/9f/on_progress_and_prosperity/12p) that considers a "scorched earth" strategy in the context of differential intellectual progress (this is also something to think about regarding SIMADs).
---
title: Eliezer Yudkowsky on the Great Stagnation
categories: Great_Stagnation
format: markdown
...

In scattered places Eliezer Yudkowsky has written about the [Great Stagnation]().

["Intelligence Explosion Microeconomics"](https://intelligence.org/files/IEM.pdf):

> I am in fact such a true cynic and I suspect that social factors dilute average contributions around as fast as new researchers can be added. A less cynical hypothesis would be that earlier science is easier, and later science grows more difficult at roughly the same rate that scientific output scales with more researchers being added.

[Facebook post from 2014-07-21](https://www.facebook.com/yudkowsky/posts/10152586485749228):

> When I think of the Great Stagnation I think of the FDA destroying drug development to the point where we have exploding obesity; the degradation of many sciences to the point where dieticians can't solve obesity; the fact that math papers from 1960 seem far more readable and friendly despite, or maybe because of, not having access to LaTeX; I think of university systems dying amid exploding student debt; I think of declining real median income in an environment of rising rents and healthcare costs and the aforesaid student debt; I think of barriers to entry and everyone suing everyone else and all the other forces that have driven innovation into bits because innovation in atoms is somehow a lot less profitable; I think of coal plants in the places where liquid fluoride thorium reactors should be; I think of slums that weren't still supposed to be there, and maybe wouldn't be there if things had improved for the bottom 20% in Western countries at the same rate they did between 1930 and 1970.

["Do Earths with slower economic growth have a better chance at FAI?"](https://www.greaterwrong.com/posts/FS6NCWzzP8DHp4aD4/do-earths-with-slower-economic-growth-have-a-better-chance) discusses why he thinks the Great Stagnation might be a good thing (because economic growth speeds up the development of unfriendly AI more than friendly AI).

["Living in an Inadequate World"](https://www.lesswrong.com/posts/pRibkeqBa2AxrpgT6/living-in-an-inadequate-world):

> I once encountered a case of (honest) misunderstanding from someone who thought that when I cited something as an example of civilizational inadequacy (or as I put it at the time, “People are crazy and the world is mad”), the thing I was trying to argue was that the Great Stagnation was just due to unimpressive / unqualified / low-status (“stupid”) scientists. He thought I thought that all we needed to do was take people in our social circle and have them go into biotech, or put scientists through a CFAR unit, and we’d see huge breakthroughs.

# External links

- <https://www.greaterwrong.com/search?q=eliezer+great+stagnation>
- <https://www.facebook.com/search/509414227/stories-by/str/great%20stagnation/stories-keyword/intersect>
---
title: List of discussions between Eliezer Yudkowsky and Paul Christiano
format: markdown
categories: AI_safety
...

This is a **list of discussions between Eliezer Yudkowsky and Paul Christiano**.

|Start date|End date|Venue|Thread title|Topics covered|Summary
|------|------|-------|----------------------|-----------------------------------------------------|------------------------------------|
|2015-12-27|2015-12-27|Arbital|["Behaviorist genie"](https://arbital.com/p/behaviorist/)|||
|2015-06-17|2015-12-29|Arbital|["Mindcrime"](https://arbital.com/p/mindcrime/#subpage-78)|||
|2015-06-18|2015-12-27|Arbital|["Ontology identification problem"](https://arbital.com/p/ontology_identification/)|||
|2015-06-18|2016-03-22|Arbital|["Nearest unblocked strategy"](https://arbital.com/p/nearest_unblocked/)|||
|2015-06-18|2015-06-18|Arbital|["Patch resistance"](https://arbital.com/p/patch_resistant/)|||
|2015-06-18|2015-07-14|Arbital|["Complexity of value"](https://arbital.com/p/complexity_of_value/#subpage-7h)|||
|2015-06-18|2015-06-18|Arbital|["Zermelo-Fraenkel provability oracle"](https://arbital.com/p/ZF_provability_oracle/)|||
|2015-12-29|2015-12-29|Arbital|["Modeling distant superintelligences"](https://arbital.com/p/distant_SIs/)|||
|2015-06-19|2015-12-29|Arbital|["Distant superintelligences can coerce the most probable environment of your AI"](https://arbital.com/p/probable_environment_hacking/)|||
|2016-05-17|2016-05-18|Arbital|["Show me what you've broken"](https://arbital.com/p/show_broken/)|||
|2015-06-18|2015-07-14|Arbital|["Omnipotence test for AI safety"](https://arbital.com/p/omni_test/)|||
|2015-12-27|2016-04-21|Arbital|["AI safety mindset"](https://arbital.com/p/AI_safety_mindset/)|||
|2015-12-29||Arbital|["Task-directed AGI"](https://arbital.com/p/task_agi/)|||
|2015-12-29|2016-01-03|Arbital|["Known-algorithm non-self-improving agent"](https://arbital.com/p/KANSI/)|||
|2016-03-09||Arbital|["Reflectively consistent degree of freedom"](https://arbital.com/p/reflective_degree_of_freedom/)|||
|2016-03-19|2016-03-19|Arbital|["Low impact"](https://arbital.com/p/low_impact/)|||
|2016-03-16||Arbital|["Open subproblems in aligning a Task-based AGI"](https://arbital.com/p/taskagi_open_problems/)|||
|2016-04-15|2016-04-17|Arbital|["Faithful simulation"](https://arbital.com/p/faithful_simulation/)|||
|2015-12-29|2015-12-29|Arbital|["Autonomous AGI"](https://arbital.com/p/Sovereign/)|||

# See also

- [List of discussions between Paul Christiano and Wei Dai]()

# External links

- ["My current take on the Paul-MIRI disagreement on alignability of messy AI"](https://agentfoundations.org/item?id=1129) by Jessica Taylor

---
format: markdown
categories: Cause_areas better-explanations
...

<!-- keywords:
    improving explanation worrydream
-->

**Better explanations** or **improving explanations** is a cause area working to explain ideas to people better.

Some reasons to think this is useful:

- Better explanations allow people to learn more quickly, allowing them to spend more time doing things or learning other things.
- Better explanations mean people with less talent in an area can learn things. One way to think about this is that 100 years before an idea is discovered, no human is bright enough to understand the "explanation" (whatever scattered prerequisite ideas and prior work that could in principle be built on or combined to produce an explanation); by the time the idea is discovered, only the brightest humans can understand the "explanation"; as the idea is published, more and more people can learn about the idea; when good expositions are produced, people with non-standard backgrounds or cognitive styles, or less talent can learn the idea.
- Bad explanations frustrate people, turn them away from subjects they may have liked, etc., so this would counteract this sort of effect of existing explanations.

In some cases, there may already exist good explanations, but these just aren't widely known. In that sense, resources like Luke Muehlhauser's ["The Best Textbooks on Every Subject"](http://lesswrong.com/lw/3gu/the_best_textbooks_on_every_subject/) that try to find good existing expositions can be considered part of this cause area.

"Anything that improves communication abilities or cooperation abilities of people is going to have a huge impact: on the neural side, figuring out how to better learn languages, or how to make social media work. Plus anything that makes human capital easier to acquire and multiply: better education, cognitive enhancement, downloadable skills." ([source](https://80000hours.org/2012/12/how-to-choose-a-research-topic-an-interview-with-anders-sandberg/))

# Existing work

I think the following people have thought about this, especially for technical explanations and from a human--computer interaction perspective:

- Bret Victor
- Douglas Engelbart
- Seymour Papert
- Michael Nielsen
- Christopher Olah
- Shan Carter

Also look more in the user experience community.

A lot of people have thought about mathematical exposition.

# Tractability

New interactive technology (e.g. interactive animations in web browsers) make some things easier to explain.

# See also

- [Argument mapping]()
- [UI Design]()

# External links

- [Distill](https://distill.pub/) works to produce good explanations in machine learning
